<critical_instructions>
## COST AWARENESS - READ THIS FIRST

**This pipeline costs real money via OpenRouter API calls.**

NEVER run these operations without explicit user approval:
- Any command that spawns LLM API calls
- `shelf serve` then submitting jobs via API
- `shelf api jobs start` or any job creation commands

Safe operations (can run freely):
- Reading files, grepping, analyzing code
- `shelf api books list`, `shelf api books get <id>`
- Running tests that use mocks
- Building and running server without submitting jobs

**Always ask first**
</critical_instructions>

<project_status>
## Project Status

This is a Go-based book digitization pipeline using DefraDB as the data layer.

**Active development branch:** `main`

The project was rewritten from Python to Go (completed in January 2025). The Go implementation uses:
- DefraDB for data storage with versioning and attribution
- Server-centric job architecture with rate-limited workers
- Parallel provider execution (OpenRouter, Mistral, DeepInfra)
- Hot-reloadable configuration
- Clean job/worker separation

### Tracking

Master tracking issue for the rewrite: [#119](https://github.com/jackzampolin/shelf/issues/119)
</project_status>

<go_implementation>
## Go Implementation

### Architecture

```
shelf/
â”œâ”€â”€ cmd/shelf/           # CLI entry point (Cobra)
â”‚   â”œâ”€â”€ main.go
â”‚   â”œâ”€â”€ root.go
â”‚   â”œâ”€â”€ serve.go         # Server command
â”‚   â”œâ”€â”€ api.go           # API CLI commands (shelf api ...)
â”‚   â””â”€â”€ version.go       # Version command
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/             # Endpoint interface + HTTP client
â”‚   â”‚   â”œâ”€â”€ endpoint.go  # Endpoint interface (Route + Command)
â”‚   â”‚   â”œâ”€â”€ registry.go  # Route registration
â”‚   â”‚   â”œâ”€â”€ client.go    # HTTP client for CLI
â”‚   â”‚   â””â”€â”€ output.go    # Output formatting
â”‚   â”œâ”€â”€ svcctx/          # Services context (dependency injection)
â”‚   â”‚   â””â”€â”€ svcctx.go    # Services struct + extractors
â”‚   â”œâ”€â”€ server/
â”‚   â”‚   â”œâ”€â”€ server.go    # HTTP server + lifecycle
â”‚   â”‚   â””â”€â”€ endpoints/   # Endpoint implementations
â”‚   â”‚       â”œâ”€â”€ health.go          # health, ready, status
â”‚   â”‚       â”œâ”€â”€ jobs_*.go          # Job CRUD and management
â”‚   â”‚       â”œâ”€â”€ books_*.go         # Book operations
â”‚   â”‚       â”œâ”€â”€ metrics_*.go       # Cost tracking and metrics
â”‚   â”‚       â”œâ”€â”€ llmcalls.go        # LLM call history
â”‚   â”‚       â”œâ”€â”€ agent_logs.go      # Agent execution logs
â”‚   â”‚       â”œâ”€â”€ pages.go           # Page operations
â”‚   â”‚       â”œâ”€â”€ prompts.go         # Prompt management
â”‚   â”‚       â”œâ”€â”€ settings.go        # Settings management
â”‚   â”‚       â””â”€â”€ registry.go        # All() helper
â”‚   â”œâ”€â”€ home/            # Home directory (~/.shelf)
â”‚   â”œâ”€â”€ config/          # Config with hot-reload
â”‚   â”œâ”€â”€ defra/           # DefraDB client + Docker management
â”‚   â”œâ”€â”€ providers/       # LLM/OCR provider workers
â”‚   â”œâ”€â”€ jobs/            # Job implementations
â”‚   â”‚   â”œâ”€â”€ common/            # Shared job utilities
â”‚   â”‚   â”œâ”€â”€ metadata_book/     # Book metadata extraction
â”‚   â”‚   â”œâ”€â”€ ocr_book/          # OCR processing
â”‚   â”‚   â”œâ”€â”€ label_book/        # Page labeling
â”‚   â”‚   â”œâ”€â”€ toc_book/          # ToC extraction
â”‚   â”‚   â”œâ”€â”€ link_toc/          # ToC linking
â”‚   â”‚   â”œâ”€â”€ common_structure/  # Structure extraction
â”‚   â”‚   â”œâ”€â”€ finalize_toc/      # ToC finalization
â”‚   â”‚   â””â”€â”€ process_book/      # Full pipeline orchestration
â”‚   â”œâ”€â”€ agent/           # LLM agent with tool use
â”‚   â”œâ”€â”€ agents/          # Specialized agents
â”‚   â”‚   â”œâ”€â”€ toc_finder/        # ToC detection
â”‚   â”‚   â”œâ”€â”€ toc_entry_finder/  # ToC entry extraction
â”‚   â”‚   â”œâ”€â”€ chapter_finder/    # Chapter boundary detection
â”‚   â”‚   â”œâ”€â”€ gap_investigator/  # Gap analysis
â”‚   â”‚   â””â”€â”€ pattern_analyzer/  # Pattern detection
â”‚   â”œâ”€â”€ llmcall/         # LLM call tracking
â”‚   â”œâ”€â”€ metrics/         # Cost and usage metrics
â”‚   â”œâ”€â”€ prompts/         # Prompt templates
â”‚   â”œâ”€â”€ schema/          # DefraDB schemas
â”‚   â”‚   â””â”€â”€ schemas/     # GraphQL schema definitions
â”‚   â”œâ”€â”€ ingest/          # PDF ingestion
â”‚   â”œâ”€â”€ jobcfg/          # Job configuration
â”‚   â””â”€â”€ testutil/        # Testing utilities
â”œâ”€â”€ web/                 # Frontend (React + TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/         # OpenAPI client
â”‚   â”‚   â”œâ”€â”€ components/  # React components
â”‚   â”‚   â”œâ”€â”€ routes/      # Page routes
â”‚   â”‚   â””â”€â”€ lib/         # Utilities
â”‚   â””â”€â”€ dist/            # Built assets
â”œâ”€â”€ docs/decisions/      # Architecture Decision Records
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â”œâ”€â”€ Makefile
â””â”€â”€ version/             # Version information
```

### Key Patterns

**1. DefraDB is source of truth** - Not files
```go
// Query progress from DefraDB, not filesystem
pages, _ := defra.Query(ctx, `{ pages(filter: {...}) { ... } }`)
```

**DefraDB Schema Limitations:**
- **No NonNull fields** - Use `field: String` not `field: String!`
- Schemas in `internal/schema/schemas/*.graphql`

**2. Jobs for all mutations**
```go
// All work goes through jobs
job, _ := jobManager.Submit(ctx, &OcrJob{BookID: "..."})
```

**3. Provider workers with rate limits**
```go
// Each provider has its own goroutine + rate limiter
resp, _ := providers.Get("openrouter").Chat(ctx, req)
```

**4. Metrics recorded per-call**
```go
// Every LLM call creates a metric record
metrics.RecordLLMCall(ctx, opts, resp)
```

**5. Unified endpoint pattern** - Each endpoint defines both HTTP route and CLI command (ADR 007)
```go
// internal/api/endpoint.go
type Endpoint interface {
    Route() (method, path string, handler http.HandlerFunc)
    RequiresInit() bool
    Command(getServerURL func() string) *cobra.Command
}

// Endpoints implement both HTTP handler and CLI command
// See internal/server/endpoints/ for implementations
```

**6. Services context** - Dependencies via context, not constructors (ADR 007)
```go
// Handlers extract services from context
func (e *ListJobsEndpoint) handler(w http.ResponseWriter, r *http.Request) {
    jm := svcctx.JobManagerFrom(r.Context())
    jobs, _ := jm.List(r.Context(), filter)
}

// Available extractors in internal/svcctx/:
// - svcctx.DefraClientFrom(ctx)
// - svcctx.JobManagerFrom(ctx)
// - svcctx.RegistryFrom(ctx)
// - svcctx.SchedulerFrom(ctx)
// - svcctx.LoggerFrom(ctx)
```

### CLI Commands

**Prefer `shelf api` over raw curl** - The CLI commands are easier to use and handle auth/formatting:

```bash
# Server management
shelf serve                    # Start server (with DefraDB)

# API commands (talk to running server) - USE THESE INSTEAD OF CURL
shelf api health               # Basic health check
shelf api ready                # Readiness check (includes DefraDB)
shelf api status               # Detailed status

# Book management
shelf api books list           # List all books
shelf api books get <id>       # Get book details
shelf api books ingest <pdf>   # Ingest a PDF scan
shelf api books cost <id>      # Get book processing cost

# Job management
shelf api jobs list            # List all jobs
shelf api jobs list --status running --type ocr-pages
shelf api jobs get <id>        # Get job details
shelf api jobs start <book-id> # Start processing a book
shelf api jobs status <book-id> # Get job status for a book
shelf api jobs create --type ocr-pages
shelf api jobs update <id> --status completed
shelf api jobs delete <id>     # Delete a job

# Metrics and monitoring
shelf api metrics list         # List all metrics
shelf api metrics summary      # Get metrics summary
shelf api llmcalls list        # List LLM call history

# Settings and configuration
shelf api settings get         # Get current settings
shelf api settings update      # Update settings
```

**Debug config:** Agent logs are only saved when `defaults.debug_agents` is `true` in job config.

### Environment

```bash
# Build and install (builds both frontend and backend)
make install

# Run server
shelf serve

# Run tests
make test

# Development - backend only (faster iteration)
make build:backend
./build/shelf serve

# View all available make targets
make help
```

### Reference Projects

**defra-mongo-connector** - `/Users/johnzampolin/go/src/github.com/sourcenetwork/defra-mongo-connector`
Use this for patterns on:
- CLI structure (Cobra commands, flags)
- Docker container management (`internal/dockerutil/`)
- Config with viper + hot-reload (`internal/connector/config.go`)
- Integration testing patterns

**DefraDB source** - `/Users/johnzampolin/go/src/github.com/sourcenetwork/defradb`
Local copy of DefraDB for understanding the database internals, client API, and query patterns.

**DefraDB docs** - https://docs.source.network/
</go_implementation>

<git_workflow>
## Git Workflow

**Branch strategy:**
- `main` - Active development (Go implementation)

**Commits:**
```bash
<type>: <imperative summary>

<body explaining what/why>

ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
```

**Commit types:** feat, fix, refactor, docs, chore, test

**Do NOT:**
- Force push to `main`
- Skip the co-author attribution
</git_workflow>

<architecture_decisions>
## Architecture Decisions

`docs/decisions/` contains Architecture Decision Records (ADRs).

**Core ADRs:**
- **000 (Information Hygiene)** - Context clarity as first principle
- **001 (Cordon Sanitaire)** - Temporal boundaries (past/present/future)
- **002 (Cost Tracking)** - Economics shape architecture
- **003 (File Organization)** - Small files, one concept per file
- **004 (Naming Conventions)** - Consistent naming patterns
- **005 (DefraDB Source of Truth)** - DefraDB as single source of truth
- **006 (Worker Architecture)** - Pool-based worker architecture
- **007 (Services Context)** - Dependency injection via context, unified endpoint pattern
- **008 (Config and Prompts in Database)** - Store configuration in DefraDB

Read the ADRs in `docs/decisions/` to understand design rationale.
</architecture_decisions>

<remember>
## Remember - Critical Checklist

**1. COST AWARENESS**
- NEVER run LLM operations without approval
- Test with mocks, not real API calls
- Jobs that call LLMs: `ocr_book`, `label_book`, `toc_book`, `link_toc`, `common_structure`, `finalize_toc`

**2. DEFRADB**
- All state in DefraDB, not files
- Jobs for mutations
- Provider workers for rate limits
- **NO NonNull fields** - DefraDB doesn't support `!` in GraphQL schemas (e.g., use `key: String` not `key: String!`)

**3. ENDPOINT PATTERN**
- Each endpoint defines both HTTP route AND CLI command
- Services come from context (`svcctx.JobManagerFrom(ctx)`)
- Add new endpoints to `internal/server/endpoints/`
- Register in `endpoints.All()` helper

**4. JOB SYSTEM**
- Job implementations in `internal/jobs/*/`
- Each job type has its own package
- Jobs communicate via DefraDB state changes
- Use `shelf api jobs start <book-id>` to process books

**5. TESTING**
- Run tests: `make test`
- Run all tests (including integration): `make test:all`
- Test with coverage: `make test:coverage`
- Frontend tests: `make web:test`
- Use mocks for LLM/OCR providers in tests
</remember>
